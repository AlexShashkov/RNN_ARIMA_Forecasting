# -*- coding: utf-8 -*-
"""GISTEMP_RESLSTM_STACKING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n_KSZ5BHdZT5ArfRhH5VojPBCYy632Kk

NASA GISS SURFACE TEMPERATURE

# Imports
"""

!pip install pmdarima

!pip install ray

import matplotlib.pyplot as plt
import pandas as pd
import torch

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from statsmodels.tsa.seasonal import STL

from torch.utils.data import TensorDataset, DataLoader
import torch.optim as optim

from torch import nn
import torch.jit as jit
import torch.nn.functional as F
import numpy as np
from ray import tune

from datetime import datetime

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

torch.autograd.set_detect_anomaly(True)

"""# NN classes

## Models and custom cells
"""

class Trainer:
    def __init__(self, model, loss_fn, optimizer):
        self.model = model
        self.model.to(device)
        self.loss_fn = loss_fn
        self.optimizer = optimizer
        self.train_losses = []
        self.val_losses = []
    
    def train_step(self, x, y):
        self.model.train()
        yhat = self.model(x)
        loss = self.loss_fn(y, yhat)
        loss.backward()

        self.optimizer.step()
        self.optimizer.zero_grad()
        return loss.item()

    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):
        model_path = f'models/{self.model}_{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'

        for epoch in range(1, n_epochs + 1):
            batch_losses = []
            for x_batch, y_batch in train_loader:
                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)
                y_batch = y_batch.to(device)
                loss = self.train_step(x_batch, y_batch)
                batch_losses.append(loss)
            training_loss = np.mean(batch_losses)
            self.train_losses.append(training_loss)

            with torch.no_grad():
                batch_val_losses = []
                # print("validation start")
                for x_val, y_val in val_loader:
                    # print("validation set", x_val, y_val)
                    x_val = x_val.view([batch_size, -1, n_features]).to(device)
                    y_val = y_val.to(device)
                    self.model.eval()
                    yhat = self.model(x_val)
                    val_loss = self.loss_fn(y_val, yhat).item()
                    batch_val_losses.append(val_loss)
                # print("validation stop")
                validation_loss = np.mean(batch_val_losses)
                self.val_losses.append(validation_loss)

            if (epoch <= 10) | (epoch % 50 == 0):
                print(
                    f"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\t Validation loss: {validation_loss:.4f}"
                )

        # torch.save(self.model.state_dict(), model_path)

    def evaluate(self, test_loader, batch_size=1, n_features=1):
      with torch.no_grad():
          predictions = []
          values = []
          for x_test, y_test in test_loader:
              x_test = x_test.view([batch_size, -1, n_features]).to(device)
              y_test = y_test.to(device)
              self.model.eval()
              yhat = self.model(x_test)
              predictions.append(yhat.detach().cpu().numpy())
              values.append(y_test.detach().cpu().numpy())

      return predictions, values

    def evaluateFromArrays(self, X, y, n_features=1):
      X = torch.Tensor(X)
      y = torch.Tensor(y)
      with torch.no_grad():
          prediction = None
          real = None
          x_test = X.view([1, -1, n_features]).to(device)
          y_test = y.to(device)
          self.model.eval()
          yhat = self.model(x_test)
          prediction = yhat.detach().cpu().numpy()
          real = y_test.detach().cpu().numpy()

      return prediction[0], real

    def plot_losses(self):
        plt.plot(self.train_losses, label="Training loss")
        plt.plot(self.val_losses, label="Validation loss")
        plt.legend()
        plt.title("Losses")
        plt.show()
        plt.close()

class RNNModel(nn.Module):
    """
    Classic RNN model
    """
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        super(RNNModel, self).__init__()
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim

        # RNN layers
        self.rnn = nn.RNN(
            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob
        )
        # Fully connected layer
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)
        out, h0 = self.rnn(x, h0.detach())
        out = out[:, -1, :]
        out = self.fc(out)
        return out

class LSTMModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        super(LSTMModel, self).__init__()
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim

        # LSTM layers
        self.lstm = nn.LSTM(
            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob
        )

        # Fully connected layer
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)
        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)
        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))
        out = out[:, -1, :]
        out = self.fc(out)
        return out

class GRUModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        super(GRUModel, self).__init__()
        self.layer_dim = layer_dim
        self.hidden_dim = hidden_dim

        # GRU layers
        self.gru = nn.GRU(
            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob
        )

        # Fully connected layer
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        # Initializing hidden state for first input with zeros
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)
        out, _ = self.gru(x, h0.detach())
        out = out[:, -1, :]
        out = self.fc(out)

        return out

"""ResLSTM"""

class ResLSTMLayer(nn.Module):
    """
    For this layer input_dim = hidden_dim = output_dim
    """
    def __init__(self, input_dim, dimension, layer_dim, dropout_prob, batch_first=True):
        super(ResLSTMLayer, self).__init__()
        # print("Creating Residual LSTM", input_dim, dimension, layer_dim, dropout_prob)

        # LSTM layers
        self.lstm = nn.LSTM(input_dim, dimension, layer_dim, batch_first=batch_first, dropout=dropout_prob)
        self.lstm.to(device)

    def forward(self, x, bus):
        # print("forwarding inside residual layer")
        # print(x, h, c)
        h = bus[0]
        c = bus[1]
        out, (hn, cn) = self.lstm(x, (h, c))
        out = out + x

        return [out, (hn, cn)]

class ResLSTMModel(nn.Module):
    """
    Basic residual LSTM model
    input_dim - dimension of input
    hidden_dim - dimension of hidden layers
    layer_dim - layers count between shortcut connections
    layers_count - count of residual blocks
    output_dim - dimension of output
    dropout_prob - dropout probability on each layer
    """
    def __init__(self, input_dim, hidden_dim, layer_dim, layers_count, output_dim, dropout_prob):
        super(ResLSTMModel, self).__init__()
        print("Creating Residual LSTM model", input_dim, hidden_dim, layer_dim, layers_count, output_dim, dropout_prob)

        # Defining the number of layers and the nodes in each layer
        self.hidden_dim = hidden_dim
        self.shortcut_layer_dim = layer_dim
        self.layer_dim = layer_dim

        self.layers = []
        reslstm = nn.LSTM(input_dim, hidden_dim, layer_dim, dropout=dropout_prob, batch_first=True)
        reslstm.to(device)
        self.layers.append(reslstm)
        for i in range(layers_count-1):
          reslstm = ResLSTMLayer(hidden_dim, hidden_dim, layer_dim, dropout_prob, batch_first=True)
          reslstm.to(device)
          self.layers.append(reslstm)

        # final lstm layer
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, layer_dim, dropout=dropout_prob, batch_first=True)
        self.lstm.to(device)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)
        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)

        for layer in self.layers:
          # print("forwarding full layer")
          x, bus = layer(x, (h0.detach(), c0.detach()))
          h0, c0 = bus[0], bus[1]
          

        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))
        out = out[:, -1, :]
        out = self.fc(out)

        return out

"""## Ensembles

Stack creator
"""

class Stack(nn.Module):
    def __init__(self, models, hidden_dim, output_dim, disable_grad_f):
        super(Stack,self).__init__()
        self.models = list(map(disable_grad_f, models))
        
        self.l_in = nn.Linear(len(self.models)*output_dim, hidden_dim, bias=False)        
        self.l_out = nn.Linear(hidden_dim, output_dim, bias=False)

        print("models count in stack:", len(self.models))
          
    def forward(self,x):
      outputs = []
      for net in self.models: outputs.append(net(x))
      # print(len(outputs), outputs[0].shape)
      out = torch.cat(outputs, 1)
      out1 = F.relu(self.l_in(out))
      out2 = self.l_out(out1)
      return out2

"""Averaging ensemble"""

from functools import reduce

class SumEnsemble(nn.Module):
    def __init__(self, models, hidden_dim, output_dim, disable_grad_f):
        super(SumEnsemble, self).__init__()
        self.models = list(map(disable_grad_f, models))

        self.l_in = nn.Linear(output_dim, hidden_dim, bias=False)  
        self.l_out = nn.Linear(hidden_dim, output_dim, bias=False)

    def forward(self, x):
        outputs = []
        for net in self.models: outputs.append(net(x))
        out = reduce(lambda x, y: x+y, outputs)
        out1 = F.relu(self.l_in(out))
        out2 = self.l_out(out1)
        return out2

"""# Helper functions"""

!mkdir models

def createDataset(dataset, input_n, horizon):
    X, y, div = [], [], []
    for i in range(len(dataset)-horizon-input_n):
        # print(f"x: {i}:{i+input_n}; y: {i+input_n}:{i+input_n+horizon}")
        feature = dataset.iloc[i:i+input_n]
        target = dataset.iloc[i+input_n:i+input_n+horizon]
        # print(feature, "=>", target)
        div.append(feature.iloc[-1].value)
        # target = target / feature.iloc[-1]
        # feature = feature / feature.iloc[-1]
        X.append(feature["value"].values)
        y.append(target["value"].values)
    X, y = pd.DataFrame(X, columns =[f"I{i}" for i in range(input_n)]), pd.DataFrame(y, columns =[f"H{i}" for i in range(horizon)])
    return (X, y, div)

def train_val_test_split(X, y, val_ratio):
    X_test, y_test = X.iloc[-1], y.iloc[-1]
    X_train, X_val, y_train, y_val = train_test_split(X.iloc[:-1], y.iloc[:-1], test_size=val_ratio, shuffle=False)
    return X_train, X_val, X_test, y_train, y_val, y_test

def inverse_transform(scaler, df, columns):
    for col in columns:
        df[col] = scaler.inverse_transform(df[col])
    return df


def format_predictions(predictions, values, df_test, scaler=None, concat=None):
    if concat is not None:
      values = np.concatenate(values, axis=concat).ravel()
      predictions = np.concatenate(predictions, axis=concat).ravel()
    df_result = pd.DataFrame(data={"value": values, "prediction": predictions}, index=df_test.head(len(values)).index)
    df_result = df_result.sort_index()
    if scaler is not None: df_result = inverse_transform(scaler, df_result, [["value", "prediction"]])
    return df_result

def calculate_metrics(df):
    return{
        'mae' : mean_absolute_error(df.value, df.prediction),
        'rmse' : mean_squared_error(df.value, df.prediction) ** 0.5
    }
            # 'r2' : r2_score(df.value, df.prediction)}

def scaleData(scaler, X_train, X_val, X_test, y_train, y_val, y_test):
  X_train_arr = scaler.fit_transform(X_train)
  X_val_arr = scaler.transform(X_val)
  X_test_arr = scaler.transform(X_test)

  y_train_arr = scaler.fit_transform(y_train)
  y_val_arr = scaler.transform(y_val)
  y_test_arr = scaler.transform(y_test)
  return (X_train_arr, X_val_arr, X_test_arr, y_train_arr, y_val_arr, y_test_arr)

def createTrainers(X_train_arr, y_train_arr, X_val_arr, y_val_arr, batch_size):
  train_features = torch.Tensor(X_train_arr)
  train_targets = torch.Tensor(y_train_arr)
  val_features = torch.Tensor(X_val_arr)
  val_targets = torch.Tensor(y_val_arr)

  train = TensorDataset(train_features, train_targets)
  val = TensorDataset(val_features, val_targets)

  train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)
  val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)

  return (train_loader, val_loader)

"""# Data"""

!wget https://raw.githubusercontent.com/datasets/global-temp-anomalies/master/data/global-temp-annual.csv -O gistemp.csv

dohody = pd.read_table('gistemp.csv', delimiter=',')[['Year', 'Land']]
# dohody[0] = pd.date_range(start='1/1993', end= '2/2019', freq = 'M')
dohody = dohody.set_index(['Year'])
dohody = dohody.rename(columns={'Land': 'value'})

plt.figure(figsize=(12, 5))
plt.plot(dohody)
plt.suptitle('Ежегодные аномальные температуры')
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(dohody.tail(36))
plt.show()

"""Lets deseason data"""

df = dohody

# Trend, seasional and residual values
res = STL(df, period = 12).fit()
trend = res.trend
seasonal = res.seasonal
residual = res.resid
deseasoned = trend + residual

plt.plot(trend)
plt.plot(seasonal)

"""Не требуется ввиду изначальной нормализации датасета

scaler = MinMaxScaler()
scaler.fit(deseasoned.values.reshape(-1, 1))
df = pd.DataFrame(np.transpose([deseasoned.index, scaler.transform(deseasoned.values.reshape(-1, 1)).reshape(313,)]), columns=["Datetime", "value"])
df = df.set_index(['Datetime'])
df.index = pd.to_datetime(df.index)
if not df.index.is_monotonic:
    df = df.sort_index()
"""

df["value"]

input_dim = 8
outpur_dim = 4
X, y, div = createDataset(df, input_dim, outpur_dim)

# X = X.applymap(np.log)
# y = y.applymap(np.log)
X

X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)
print(list(map(len, (X_train, X_val, X_test, y_train, y_val, y_test))))
# scaler = MinMaxScaler()
# X_train_arr, X_val_arr, y_train_arr, y_val_arr = scaleData(scaler, X_train, X_val, y_train, y_val)
# batch_size = 32
# train_loader, val_loader = createTrainers(X_train.values, y_train.values, X_val.values, y_val.values, batch_size)

"""# ARIMA"""

from statsmodels.tsa.arima.model import ARIMA
import pmdarima as pm

x_train = df[:-12]

# Seasonal - fit stepwise auto-ARIMA
smodel = pm.auto_arima(x_train, start_p=1, start_q=1,
                         test='adf',
                         max_p=3, max_q = 3, m = 12,
                         start_P=0, seasonal=True,
                         d=None, D=1, trace=True,
                         error_action='ignore',  
                         suppress_warnings=True, 
                         stepwise=True)

# Forecast
fitted, confint = smodel.predict(12, return_conf_int = True)
fitted = fitted.values
values = df[-12:].values

# make series for plotting purpose
fitted_series = pd.Series(fitted)
lower_series = pd.Series(confint[:, 0])
upper_series = pd.Series(confint[:, 1])

# fitted = scaler.inverse_transform(fitted.values.reshape(-1, 1)).squeeze() # np.exp(predictions) # *div[-1]
# values = scaler.inverse_transform(df[-12:].values.reshape(-1, 1)).squeeze() # np.exp(values) # *div[-1]

# Plot
plt.figure(figsize=(5, 4))
plt.plot(values, label = 'x_valid')
plt.plot(fitted, label = 'predicted')
plt.tick_params(axis = 'x', labelrotation = 30)

plt.legend()
plt.title("S_ARIMA prediction")
plt.show()

print(
    {
        'mae' : mean_absolute_error(values, fitted),
        'rmse' : mean_squared_error(values, fitted) ** 0.5
    }
)

"""# ETS"""

from statsmodels.tsa.exponential_smoothing.ets import ETSModel

x_train = dohody[:-12]

model = ETSModel(x_train.values.reshape(-1),
                seasonal='add',
                seasonal_periods=12)
fit = model.fit(maxiter = 10)

# spots.plot(label="data")
fitted = fit.fittedvalues

plt.figure(figsize = (12, 4))
plt.plot(fitted, label = 'fitted')
plt.plot(x_train.values.reshape(-1), label = 'x_train')
plt.suptitle('ETC, fit')
plt.legend()
plt.show()

fitted = fit.predict()[-12:]
values = df[-12:].values.reshape(-1, 1) # np.exp(values) # *div[-1]

# Plot
plt.figure(figsize=(5, 4))
plt.plot(values, label = 'x_valid')
plt.plot(fitted, label = 'predicted')
plt.tick_params(axis = 'x', labelrotation = 30)

plt.legend()
plt.title("ETS prediction")
plt.show()

print(
    {
        'mae' : mean_absolute_error(values, fitted),
        'rmse' : mean_squared_error(values, fitted) ** 0.5
    }
)

"""# Tuning Basic

## Grid Search LSTM
"""

config = {
    "learning_rate":  tune.grid_search([1e-3]),
    "batch_size": tune.grid_search([4, 8, 16]),
    "input_dim": tune.grid_search([12, 24, 36]),
    "hidden_dim": tune.grid_search([96, 128]),
    "layer_dim" : tune.grid_search([3, 4]),
    "dropout" : tune.grid_search([0.1, 0.2]),
    "delta": tune.grid_search([1.0, 1.5])
}

f = open("/content/bestmae.txt", "w")
f.write("999999999999.0")
f.close()

def train_wrapper(config):
  input_dim = config["input_dim"]
  output_dim = 12
  X, y, div = createDataset(df, input_dim, output_dim)
  X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)
  train_loader, val_loader = createTrainers(X_train.values, y_train.values, X_val.values, y_val.values, config["batch_size"])

  n_epochs = 12
  weight_decay = 1e-6

  model_params = {
      'input_dim': input_dim,
      'output_dim' : output_dim,
      'hidden_dim' : config["hidden_dim"],
      'layer_dim' : config["layer_dim"],
      'dropout_prob' : config["dropout"]
}

  model = LSTMModel(**model_params)

  # loss_fn = nn.MSELoss(reduction="mean")
  loss_fn = nn.HuberLoss(reduction='mean', delta=config["delta"])
  # loss_fn = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.parameters(), lr=config["learning_rate"], weight_decay=weight_decay)

  opt = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer)
  opt.train(train_loader, val_loader, batch_size=config["batch_size"], n_epochs=n_epochs, n_features=input_dim)
  predictions, values = opt.evaluateFromArrays(X_test, y_test, n_features=input_dim)

  # print("PRED:", predictions)
  # print("REAL:", values)
  df_result = format_predictions(predictions, values, X_test)
  result_metrics = calculate_metrics(df_result)

  f = open("/content/bestmae.txt", "r")
  mae = float(f.read())
  f.close()

  if result_metrics["mae"] < mae:
    print("OLD MAE:", mae)
    torch.save(opt.model.state_dict(), "/content/GISTEMP_best_LSTM.pt")
    f = open("/content/bestmae.txt", "w")
    f.write(str(result_metrics["mae"]))
    f.close()
  tune.report(accuracy=result_metrics["mae"])

analysis = tune.run(
  train_wrapper,
  config=config,
  resources_per_trial={"cpu": 2, "gpu": 1}
)
best_trial = analysis.get_best_trial("accuracy", "min", "last")
print("Best trial config: {}".format(best_trial.config))
print("Best trial final validation accuracy (MAE): {}".format(
    best_trial.last_result["accuracy"]))

"""## LSTM"""

config = {
    "input_dim": 36,
    'output_dim' : 12,
    "hidden_dim": 128,
    "layer_dim" : 3,
    'dropout_prob' : 0.2
}

Lmodel = LSTMModel(**config)
Lmodel.load_state_dict(torch.load("/content/GISTEMP_best_LSTM.pt"))
Lmodel.eval()

Lopt = Trainer(model=Lmodel, loss_fn=None, optimizer=None)

X, y, div = createDataset(df, 36, 12)
X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)

Lpredictions, values = Lopt.evaluateFromArrays(X_test, y_test, n_features=36)

print("PRED:", Lpredictions)
print("REAL:", values)
# Plot
plt.figure(figsize=(5, 4))
plt.plot(values, label = 'x_valid')
plt.plot(Lpredictions, label = 'predicted')
plt.tick_params(axis = 'x', labelrotation = 30)

plt.legend()
plt.title("LSTM prediction")
plt.show()

"""## Grid Search GRU"""

config = {
    "learning_rate":  tune.grid_search([1e-3]),
    "batch_size": tune.grid_search([4, 8, 16]),
    "input_dim": tune.grid_search([12, 24, 36]),
    "hidden_dim": tune.grid_search([96, 128]),
    "layer_dim" : tune.grid_search([3, 4]),
    "dropout" : tune.grid_search([0.1, 0.2]),
    "delta": tune.grid_search([1.0, 1.5])
}

f = open("/content/bestmae.txt", "w")
f.write("999999999999.0")
f.close()

def train_wrapper(config):
  input_dim = config["input_dim"]
  output_dim = 12
  X, y, div = createDataset(df, input_dim, output_dim)
  X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)
  train_loader, val_loader = createTrainers(X_train.values, y_train.values, X_val.values, y_val.values, config["batch_size"])

  n_epochs = 12
  weight_decay = 1e-6

  model_params = {
      'input_dim': input_dim,
      'output_dim' : output_dim,
      'hidden_dim' : config["hidden_dim"],
      'layer_dim' : config["layer_dim"],
      'dropout_prob' : config["dropout"]
}

  model = GRUModel(**model_params)

  # loss_fn = nn.MSELoss(reduction="mean")
  loss_fn = nn.HuberLoss(reduction='mean', delta=config["delta"])
  # loss_fn = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.parameters(), lr=config["learning_rate"], weight_decay=weight_decay)

  opt = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer)
  opt.train(train_loader, val_loader, batch_size=config["batch_size"], n_epochs=n_epochs, n_features=input_dim)
  predictions, values = opt.evaluateFromArrays(X_test, y_test, n_features=input_dim)

  # print("PRED:", predictions)
  # print("REAL:", values)
  df_result = format_predictions(predictions, values, X_test)
  result_metrics = calculate_metrics(df_result)

  f = open("/content/bestmae.txt", "r")
  mae = float(f.read())
  f.close()

  if result_metrics["mae"] < mae:
    print("OLD MAE:", mae)
    torch.save(opt.model.state_dict(), "/content/GISTEMP_best_GRU.pt")
    f = open("/content/bestmae.txt", "w")
    f.write(str(result_metrics["mae"]))
    f.close()
  tune.report(accuracy=result_metrics["mae"])

analysis = tune.run(
  train_wrapper,
  config=config,
  resources_per_trial={"cpu": 2, "gpu": 1}
)
best_trial = analysis.get_best_trial("accuracy", "min", "last")
print("Best trial config: {}".format(best_trial.config))
print("Best trial final validation accuracy (MAE): {}".format(
    best_trial.last_result["accuracy"]))

"""## GRU"""

config = {
    "input_dim": 36,
    'output_dim' : 12,
    "hidden_dim": 96,
    "layer_dim" : 3,
    'dropout_prob' : 0.2
}

Gmodel = GRUModel(**config)
Gmodel.load_state_dict(torch.load("/content/GISTEMP_best_GRU.pt"))
Gmodel.eval()

Gopt = Trainer(model=Gmodel, loss_fn=None, optimizer=None)

X, y, div = createDataset(df, 36, 12)
X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)

Gpredictions, values = Gopt.evaluateFromArrays(X_test, y_test, n_features=36)

print("PRED:", Gpredictions)
print("REAL:", values)
# Plot
plt.figure(figsize=(5, 4))
plt.plot(values, label = 'x_valid')
plt.plot(Gpredictions, label = 'predicted')
plt.tick_params(axis = 'x', labelrotation = 30)

plt.legend()
plt.title("GRU prediction")
plt.show()

"""## Grid Search Residual LSTM"""

config = {
    "learning_rate":  tune.grid_search([1e-3]),
    "batch_size": tune.grid_search([4, 8, 16]),
    "input_dim": tune.grid_search([12, 24, 36]),
    "hidden_dim": tune.grid_search([96, 128]),
    "layer_dim" : tune.grid_search([3, 4]),
    "dropout" : tune.grid_search([0.1, 0.2]),
    "delta": tune.grid_search([1.0, 1.5])
}

f = open("/content/bestmae.txt", "w")
f.write("999999999999.0")
f.close()

def train_wrapper(config):
  input_dim = config["input_dim"]
  output_dim = 12
  X, y, div = createDataset(df, input_dim, output_dim)
  X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)
  train_loader, val_loader = createTrainers(X_train.values, y_train.values, X_val.values, y_val.values, config["batch_size"])

  n_epochs = 12
  weight_decay = 1e-6

  model_params = {
      'input_dim': input_dim,
      'output_dim' : output_dim,
      'hidden_dim' : config["hidden_dim"],
      'layers_count' : config["layer_dim"],
      'layer_dim' : 1,
      'dropout_prob' : config["dropout"]
  }

  model = ResLSTMModel(**model_params)

  # loss_fn = nn.MSELoss(reduction="mean")
  loss_fn = nn.HuberLoss(reduction='mean', delta=config["delta"])
  # loss_fn = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.parameters(), lr=config["learning_rate"], weight_decay=weight_decay)

  opt = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer)
  opt.train(train_loader, val_loader, batch_size=config["batch_size"], n_epochs=n_epochs, n_features=input_dim)
  predictions, values = opt.evaluateFromArrays(X_test, y_test, n_features=input_dim)

  # print("PRED:", predictions)
  # print("REAL:", values)
  df_result = format_predictions(predictions, values, X_test)
  result_metrics = calculate_metrics(df_result)

  f = open("/content/bestmae.txt", "r")
  mae = float(f.read())
  f.close()

  if result_metrics["mae"] < mae:
    print("OLD MAE:", mae)
    torch.save(opt.model.state_dict(), "/content/GISTEMP_best_ResLSTM.pt")
    f = open("/content/bestmae.txt", "w")
    f.write(str(result_metrics["mae"]))
    f.close()
  tune.report(accuracy=result_metrics["mae"])

analysis = tune.run(
  train_wrapper,
  config=config,
  resources_per_trial={"cpu": 2, "gpu": 1}
)
best_trial = analysis.get_best_trial("accuracy", "min", "last")
print("Best trial config: {}".format(best_trial.config))
print("Best trial final validation accuracy (MAE): {}".format(
    best_trial.last_result["accuracy"]))

"""## Residual LSTM"""

config = {
    "input_dim": 12,
    'output_dim' : 12,
    "hidden_dim": 96,
    "layers_count" : 4,
    'layer_dim' : 1,
    'dropout_prob' : 0.2
}

RLmodel = ResLSTMModel(**config)
RLmodel.load_state_dict(torch.load("/content/GISTEMP_best_ResLSTM.pt"))
RLmodel.eval()

RLopt = Trainer(model=RLmodel, loss_fn=None, optimizer=None)

X, y, div = createDataset(df, 12, 12)
X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)

RLpredictions, values = RLopt.evaluateFromArrays(X_test, y_test, n_features=12)

print("PRED:", RLpredictions)
print("REAL:", values)
# Plot
plt.figure(figsize=(5, 4))
plt.plot(values, label = 'x_valid')
plt.plot(RLpredictions, label = 'predicted')
plt.tick_params(axis = 'x', labelrotation = 30)

plt.legend()
plt.title("ResLSTM prediction")
plt.show()

"""# Ensembles"""

batch_size = 16
train_loader, val_loader = createTrainers(X_train.values, y_train.values, X_val.values, y_val.values, batch_size)

"""## Residual LSTM"""

# X, y, div = createDataset(df, 24, output_dim)
# X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)
batch_size = 4
train_loader, val_loader = createTrainers(X_train.values, y_train.values, X_val.values, y_val.values, batch_size)

input_dim = len(X_train.columns)
output_dim = len(y_train.columns)
hidden_dim = 256
layer_dim = 1
layers_count = 6
dropout = 0.4
n_epochs = 24
learning_rate = 0.001
weight_decay = 1e-6

loss_fn = nn.MSELoss(reduction="mean")
# loss_fn = nn.HuberLoss(reduction='mean', delta=1.0)
models = []
layer_props = (96, 1, 4)
for i in range(10):
  hidden_dim, layer_dim, layers_count = layer_props
  model_params = {
    'input_dim': input_dim,
    'hidden_dim' : hidden_dim,
    'layer_dim' : layer_dim,
    "layers_count" : layers_count, 
    'output_dim' : output_dim,
    'dropout_prob' : dropout
  }
  model = ResLSTMModel(**model_params)
  optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

  opt = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer)
  opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)
  models.append(opt)
  print(f"Trained model with h={hidden_dim} l={layer_dim}")

def disable_grad(layer):
    for _layer in layer.layers:
      for p in _layer.parameters():
          p.requires_grad=False
    for p in layer.parameters():
          p.requires_grad=False
    return layer

learning_rate = 0.0001
model = Stack(list(map(lambda x: x.model, models)), 512, output_dim, disable_grad)

loss_fn = nn.MSELoss(reduction="mean")
optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

opt = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer)
opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=12, n_features=input_dim)
opt.plot_losses()

predictions, values = opt.evaluateFromArrays(X_test, y_test, n_features=input_dim)
# predictions = scaler.inverse_transform(predictions.reshape(-1, 1)).squeeze() # np.exp(predictions) # *div[-1]
# values = scaler.inverse_transform(values.reshape(-1, 1)).squeeze() # np.exp(values) # *div[-1]
print("PRED:", predictions)
print("REAL:", values)

df_result = format_predictions(predictions, values, X_test, None)
result_metrics = calculate_metrics(df_result)
print(result_metrics)

# Plot
plt.figure(figsize=(5, 4))
plt.plot(values, label = 'x_valid')
plt.plot(predictions, label = 'predicted')
plt.tick_params(axis = 'x', labelrotation = 30)

plt.legend()
plt.title("ResLSTM prediction")
plt.show()

"""## Basic LSTM"""

# X, y, div = createDataset(df, 36, output_dim)
# X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, 0.2)
batch_size = 4
train_loader, val_loader = createTrainers(X_train.values, y_train.values, X_val.values, y_val.values, batch_size)

input_dim = len(X_train.columns)
output_dim = len(y_train.columns)
hidden_dim = 256
layer_dim = 4
dropout = 0.4
n_epochs = 24
learning_rate = 0.001
weight_decay = 1e-6

loss_fn = nn.HuberLoss(reduction='mean', delta=1.0)
models = []
layer_props = (96, 3, 3)
for i in range(8):
  hidden_dim, layer_dim, layers_count = layer_props
  model_params = {
    'input_dim': input_dim,
    'hidden_dim' : hidden_dim,
    'layer_dim' : layer_dim,
    # "layers_count" : layers_count, 
    'output_dim' : output_dim,
    'dropout_prob' : dropout
  }
  model = LSTMModel(**model_params)
  optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

  opt = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer)
  opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)
  models.append(opt)
  print(f"Trained model with h={hidden_dim} l={layer_dim}")

def disable_grad(layer):
    for p in layer.parameters():
          p.requires_grad=False
    return layer

learning_rate = 0.0003
model = Stack(list(map(lambda x: x.model, models)), 512, output_dim, disable_grad)

loss_fn = nn.MSELoss(reduction="mean")
optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

opt = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer)
opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=8, n_features=input_dim)
opt.plot_losses()

predictions, values = opt.evaluateFromArrays(X_test, y_test, n_features=input_dim)
# predictions = scaler.inverse_transform(predictions.reshape(-1, 1)).squeeze() # np.exp(predictions) # *div[-1]
# values = scaler.inverse_transform(values.reshape(-1, 1)).squeeze() # np.exp(values) # *div[-1]
print("PRED:", predictions)
print("REAL:", values)

df_result = format_predictions(predictions, values, X_test, None)
result_metrics = calculate_metrics(df_result)
print(result_metrics)

# Plot
plt.figure(figsize=(5, 4))
plt.plot(values, label = 'x_valid')
plt.plot(predictions, label = 'predicted')
plt.tick_params(axis = 'x', labelrotation = 30)

plt.legend()
plt.title("ResLSTM prediction")
plt.show()

"""# Summary"""

plt.figure(figsize=(5, 4))
plt.plot(values, label = 'Validation')
plt.plot(Lpredictions, label = 'LSTM prediction')
plt.plot(Gpredictions, label = 'GRU prediction')
plt.plot(RLpredictions, label = 'ResLSTM prediction')

plt.tick_params(axis = 'x', labelrotation = 30)
plt.legend()
plt.title("Models predictions")
plt.show()

yt = [0.18331, 0.13755, 0.34413, 0.07838, 0.31023]

xt = [r for r in range(len(yt))]

xlabels =  ['LSTM', 'GRU', 'RESLSTM', 'ARIMA', 'ETS']

plt.bar(xt, yt)
plt.xticks(xt, xlabels[: len(yt)])
plt.ylabel('MAE', fontweight ='bold')
plt.tick_params(axis = 'x', labelrotation = 30)

plt.suptitle('Модели на наборе GISTEMP')

plt.show()